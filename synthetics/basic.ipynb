{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10 # either vocab size or embedding size. \n",
    "# ^ it is not easy to generate samples on the probability simplex that satisfy a gaussian difference, so we stick to embeddings/unconstrained logits.\n",
    "m = 3 # number of prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta: [21.44408149  9.07740938 27.70640861]\n",
      "Sigma diag: [0.02331646 0.02331646 0.02331646 0.02331646 0.02331646 0.02331646\n",
      " 0.02331646 0.02331646 0.02331646 0.02331646 0.05508179 0.05508179\n",
      " 0.05508179 0.05508179 0.05508179 0.05508179 0.05508179 0.05508179\n",
      " 0.05508179 0.05508179 0.01804637 0.01804637 0.01804637 0.01804637\n",
      " 0.01804637 0.01804637 0.01804637 0.01804637 0.01804637 0.01804637]\n",
      "mu: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# construct groundtruth theta \"accuracies\"\n",
    "theta = np.random.random(m)*50 # all positive for now. Larger theta = less noisy LFs.\n",
    "print(\"Theta:\", theta)\n",
    "\n",
    "# construct mu and sigma for multivariate gaussian formulation of the model.\n",
    "sigma_diag = np.zeros(m*vocab_size)\n",
    "for i in range(len(sigma_diag)):\n",
    "    prompt_idx = int(i / vocab_size)\n",
    "    sigma_diag[i] = 1/(2 * theta[prompt_idx])\n",
    "\n",
    "print(\"Sigma diag:\", sigma_diag)\n",
    "\n",
    "sigma = np.diag(sigma_diag)\n",
    "mu = np.zeros(m * vocab_size)\n",
    "\n",
    "print(\"mu:\", mu) # Zero mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10000\n",
    "all_lfs_y = []\n",
    "all_diffs = []\n",
    "count = 0\n",
    "while count < n:\n",
    "    # Construct LF votes by sampling a \"diff\" according to MV gaussian, sampling a random groundtruth y\n",
    "    # and setting LF = diff + y\n",
    "    diff = np.random.multivariate_normal(mu, sigma)\n",
    "    all_diffs.append(diff)\n",
    "\n",
    "    y = np.random.random(vocab_size)\n",
    "    y_repeated = np.tile(y, reps= m)\n",
    "\n",
    "    lfs = (y_repeated + diff).reshape((m, vocab_size))\n",
    "    lfs_y = np.concatenate([lfs, y.reshape((-1, vocab_size))], axis=0)\n",
    "\n",
    "    all_lfs_y.append(lfs_y)\n",
    "    count += 1\n",
    "\n",
    "all_lfs_y = np.array(all_lfs_y)\n",
    "all_lfs_y.shape # The first three rows of the second dimension corresponds to LF, and the fourth corresponds to y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet(i, j, k):\n",
    "    diff_ij = (np.linalg.norm(all_lfs_y[:, i, :] - all_lfs_y[:, j, :], axis=1, ord=2)**2).mean()\n",
    "    diff_ik = (np.linalg.norm(all_lfs_y[:, i, :] - all_lfs_y[:, k, :], axis=1, ord=2)**2).mean()\n",
    "    diff_jk = (np.linalg.norm(all_lfs_y[:, j, :] - all_lfs_y[:, k, :], axis=1, ord=2)**2).mean()\n",
    "\n",
    "    return 0.5*(diff_ij + diff_ik - diff_jk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23288287180858308 0.23369112730365055\n",
      "0.5578053959351905 0.554497767481926\n",
      "0.1796984318051682 0.18107175815446175\n"
     ]
    }
   ],
   "source": [
    "diff = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    other_idxs = np.delete(np.arange(m), i)\n",
    "    j, k = np.random.choice(other_idxs, size=2, replace=False)\n",
    "    diff[i] = triplet(i, j, k)\n",
    "\n",
    "    print(diff[i], (np.linalg.norm(all_lfs_y[:, i, :] - all_lfs_y[:, m, :], axis=1)**2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to canonical parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.47002036  8.96369959 27.82439418] [21.44408149  9.07740938 27.70640861]\n"
     ]
    }
   ],
   "source": [
    "# convert mean parameters to canonical parameters \n",
    "theta_estimate = vocab_size/(2*diff)\n",
    "\n",
    "print(theta_estimate, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve optimization problem at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lfs = all_lfs_y[0][:m]\n",
    "true_y = all_lfs_y[0][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53693616 0.43080623 0.68649778 0.67329944 0.17628504 0.54484161\n",
      " 0.46845506 0.9088682  0.19074946 0.6546315 ] [0.54041229 0.4833929  0.62790673 0.53810944 0.20376202 0.55361529\n",
      " 0.38772711 0.87666378 0.44508623 0.61130735]\n"
     ]
    }
   ],
   "source": [
    "predicted_y = 1/theta_estimate.sum() * sample_lfs.T.dot(theta_estimate)\n",
    "print(predicted_y, true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
